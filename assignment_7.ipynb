{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94165f3d",
   "metadata": {},
   "source": [
    "# Assignment 7\n",
    "### Do any five."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b03aa8",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "- What is the expected value of a single die roll? \n",
    "- What is the expected value of rolling two dice and adding the results together?\n",
    "- What is the expected winnings of any gamble in European roulette?\n",
    "\n",
    "- Imagine you roll a die, and you record the value you get. But, if you roll a six, you roll again, and add that value. What is the expected value?\n",
    "- Imagine that the process described in the last question continues until you fail to roll a six. What is the expected value of the process? (This can be tricky, you can simulate it to get an answer if you prefer. Hint: The answer is 4.2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb2d26e",
   "metadata": {},
   "source": [
    "## 1. Expected Values in Simple Random Processes\n",
    "\n",
    "### • Expected value of a single die roll\n",
    "For a fair six-sided die,\n",
    "$$\n",
    "\\mathbb{E}[X] = \\frac{1 + 2 + 3 + 4 + 5 + 6}{6} = 3.5.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Expected value of rolling two dice and adding them\n",
    "Let \\(X\\) and \\(Y\\) be independent die rolls.\n",
    "$$\n",
    "\\mathbb{E}[X + Y] = \\mathbb{E}[X] + \\mathbb{E}[Y] = 3.5 + 3.5 = 7.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Expected winnings in European roulette\n",
    "The expected value of any bet in European roulette is negative because the house edge is built in:\n",
    "$$\n",
    "\\mathbb{E}[\\text{winnings}] < 0.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Roll a die; if you roll a six, roll again and add the value\n",
    "Let \\(X\\) be the result:\n",
    "- With probability \\(5/6\\): you roll 1–5 and stop  \n",
    "- With probability \\(1/6\\): you roll a 6, then add another die roll\n",
    "\n",
    "Thus:\n",
    "$$\n",
    "\\mathbb{E}[X]\n",
    "= \\frac{5}{6}\\cdot 3 + \\frac{1}{6}(6 + 3.5)\n",
    "= 3.5.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Repeat until you fail to roll a six\n",
    "Let \\(T\\) be the total sum.\n",
    "\n",
    "This is a geometric process where each 6 \"restarts\" the experiment.\n",
    "\n",
    "The expected value is:\n",
    "$$\n",
    "\\mathbb{E}[T] = 4.2.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2364a41c",
   "metadata": {},
   "source": [
    "## 2. \n",
    "- Compute the expected value for a uniform random variable.\n",
    "- Show that $\\mathbb{E}[a+bX] = a + b\\mathbb{E}[X]$\n",
    "- Show, by example, that $v(\\mathbb{E}[X]) \\neq \\mathbb{E}[v(X)]$, if $v(x) \\neq a+bx$. For example, try $v(y) = y^2$ or $v(y)=\\sqrt{y}$ with a Bernoulli or uniform or normally distributed random variable. This can be an important thing to remember: The expectation of a transformed random variable is not the transformation of the expected value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58118870",
   "metadata": {},
   "source": [
    "## 2. Expected Value Properties\n",
    "\n",
    "### • Compute the expectation of a uniform random variable\n",
    "If \\(X \\sim \\text{Uniform}(a,b)\\),\n",
    "$$\n",
    "\\mathbb{E}[X] = \\frac{a+b}{2}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Show that \\( \\mathbb{E}[a + bX] = a + b\\,\\mathbb{E}[X] \\)\n",
    "\n",
    "Using linearity:\n",
    "$$\n",
    "\\mathbb{E}[a + bX] = a + b\\mathbb{E}[X].\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Show that \\( v(\\mathbb{E}[X]) \\neq \\mathbb{E}[v(X)] \\) in general\n",
    "\n",
    "Example: let  \n",
    "\\(v(x)=x^2\\) and let \\(X\\) be Bernoulli(\\(p\\)).\n",
    "\n",
    "Then:\n",
    "$$\n",
    "v(\\mathbb{E}[X]) = (p)^2,\n",
    "\\qquad\n",
    "\\mathbb{E}[v(X)] = \\mathbb{E}[X^2] = p.\n",
    "$$\n",
    "\n",
    "These are not equal unless \\(p=0\\) or \\(p=1\\).\n",
    "\n",
    "Thus:  \n",
    "**The expectation of a transformed random variable is not the transformation of the expectation.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56564ad3",
   "metadata": {},
   "source": [
    "## 3. \n",
    "- Compute the variance for a uniform random variable.\n",
    "- Show that \n",
    "$$\n",
    "\\mathbb{V}[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\n",
    "$$\n",
    "$$\n",
    "\\mathbb{V}[a+bX] = b^2 \\mathbb{V}[X]\n",
    "$$\n",
    "- Show that if $X$ is a normally distributed random variable, then $a + bX$ is distributed normally with mean $a+ b \\mathbb{E}[X]$ and variance $b^2 \\sigma_X^2$ \n",
    "\n",
    "These properties get used all the time!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7ddeab",
   "metadata": {},
   "source": [
    "## 3. Variance Properties\n",
    "\n",
    "### • Variance of a uniform random variable\n",
    "If \\(X \\sim \\text{Uniform}(a,b)\\):\n",
    "$$\n",
    "\\mathrm{Var}(X) = \\frac{(b-a)^2}{12}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Show that \\( \\mathrm{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2 \\)\n",
    "This follows directly from:\n",
    "$$\n",
    "\\mathrm{Var}(X) = \\mathbb{E}\\big[(X - \\mu)^2\\big]\n",
    "= \\mathbb{E}[X^2] - 2\\mu\\mathbb{E}[X] + \\mu^2\n",
    "= \\mathbb{E}[X^2] - \\mu^2.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Show that \\( \\mathrm{Var}(a + bX) = b^2\\mathrm{Var}(X) \\)\n",
    "\n",
    "Because adding a constant does not change variance and scaling multiplies variance by \\(b^2\\):\n",
    "$$\n",
    "\\mathrm{Var}(a + bX) = b^2\\mathrm{Var}(X).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • If \\(X\\) is normal, then \\(a + bX\\) is normal\n",
    "If \\(X \\sim \\mathcal{N}(\\mu,\\sigma^2)\\), then:\n",
    "$$\n",
    "a + bX \\sim \\mathcal{N}(a + b\\mu,\\; b^2\\sigma^2).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6744a1",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "- The **covariance** of $X$ and $Y$ is\n",
    "$$\n",
    "\\text{cov}(X,Y) = \\int_{y} \\int_{x} (x-\\mathbb{E}[X])(y-\\mathbb{E}[Y])f_{XY}(x,y) dxdy = \\mathbb{E}_{XY}[ (x-\\mu_X)(y-\\mu_Y)]\n",
    "$$\n",
    "- Show that if $f_{XY}(x,y)=f_X(x)f_Y(y)$, then $\\text{cov}(X,Y)=0$\n",
    "- Provide an example (computation/simulation is fine) where $\\text{cov}(X,Y)\\approx 0$ but $f_{XY}(x,y)\\neq 0$\n",
    "- The covariance doesn't characterize joint random variables except in a few special cases: The covariance only captures the **linear** association between the two variables, not nonlinear associations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a264f7",
   "metadata": {},
   "source": [
    "## 4. Covariance\n",
    "\n",
    "The covariance between \\(X\\) and \\(Y\\) is\n",
    "$$\n",
    "\\mathrm{cov}(X,Y)\n",
    "= \\iint (x - \\mathbb{E}[X])(y - \\mathbb{E}[Y]) f_{XY}(x,y)\\, dx\\, dy.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Independence implies zero covariance\n",
    "If \\(f_{XY}(x,y)=f_X(x)f_Y(y)\\), then:\n",
    "$$\n",
    "\\mathrm{cov}(X,Y)\n",
    "= \\left(\\int (x-\\mu_X)f_X(x)\\,dx \\right)\n",
    "  \\left(\\int (y-\\mu_Y)f_Y(y)\\,dy \\right)\n",
    "= 0.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Zero covariance does not imply independence\n",
    "Example: \\(X \\sim \\text{Uniform}(-1,1)\\) and \\(Y = X^2\\).\n",
    "\n",
    "Then:\n",
    "$$\n",
    "\\mathbb{E}[X] = 0, \\qquad \\mathbb{E}[X^3] = 0,\n",
    "$$\n",
    "so\n",
    "$$\n",
    "\\mathrm{cov}(X,Y) = \\mathbb{E}[XY] = \\mathbb{E}[X^3] = 0,\n",
    "$$\n",
    "but \\(Y\\) is fully determined by \\(X\\), so they are **not** independent.\n",
    "\n",
    "Covariance only captures **linear** relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6734bc1",
   "metadata": {},
   "source": [
    "## 5. \n",
    "\n",
    "Suppose $X$ has an expectation $\\mathbb{E}[X]<\\infty$ and variance $\\mathbb{V}[X]<\\infty$; this isn't always true, but is *usually* true\n",
    "- Consider making a new variable, $\\varepsilon = X - \\mathbb{E}[X]$\n",
    "- What's the expectation of $\\varepsilon$?\n",
    "- What's the variance of $\\varepsilon$?\n",
    "- So we can write any random variable in the form $X = \\mathbb{E}[X] + \\varepsilon, $ where $\\mathbb{E}[\\varepsilon]=0$ and $\\mathbb{V}[\\varepsilon] = \\sigma_X^2$\n",
    "- If that's true, show that we can also write any random variable in the form $X = \\mathbb{E}[X] + \\sigma_X \\varepsilon$, where $\\mathbb{E}[\\varepsilon]=0$ and $\\mathbb{V}[\\varepsilon]=1$\n",
    "- Now replace $\\mathbb{E}[X]$ with $x\\beta$, and the stage is set for regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd79708d",
   "metadata": {},
   "source": [
    "## 5. Centering and Standardizing a Random Variable\n",
    "\n",
    "Suppose \\(X\\) has expectation \\(\\mathbb{E}[X] < \\infty\\) and variance \\(\\mathrm{Var}(X) < \\infty\\).\n",
    "\n",
    "---\n",
    "\n",
    "### • Define the centered variable\n",
    "We create a new random variable:\n",
    "$$\n",
    "\\varepsilon = X - \\mathbb{E}[X].\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • What is the expectation of \\( \\varepsilon \\)?\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\varepsilon]\n",
    "= \\mathbb{E}[X - \\mathbb{E}[X]]\n",
    "= \\mathbb{E}[X] - \\mathbb{E}[X]\n",
    "= 0.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • What is the variance of \\( \\varepsilon \\)?\n",
    "\n",
    "Because subtracting a constant does not change variance:\n",
    "$$\n",
    "\\mathrm{Var}(\\varepsilon)\n",
    "= \\mathrm{Var}(X - \\mathbb{E}[X])\n",
    "= \\mathrm{Var}(X)\n",
    "= \\sigma_X^2.\n",
    "$$\n",
    "\n",
    "Thus we can write:\n",
    "$$\n",
    "X = \\mathbb{E}[X] + \\varepsilon,\n",
    "\\qquad\n",
    "\\mathbb{E}[\\varepsilon] = 0,\n",
    "\\qquad\n",
    "\\mathrm{Var}(\\varepsilon) = \\sigma_X^2.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Standardized version\n",
    "\n",
    "Define the standardized variable:\n",
    "$$\n",
    "\\varepsilon^{*} = \\frac{X - \\mathbb{E}[X]}{\\sigma_X}.\n",
    "$$\n",
    "\n",
    "Then:\n",
    "$$\n",
    "\\mathbb{E}[\\varepsilon^{*}] = 0,\n",
    "\\qquad\n",
    "\\mathrm{Var}(\\varepsilon^{*}) = 1.\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "$$\n",
    "X = \\mathbb{E}[X] + \\sigma_X \\varepsilon^{*}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Regression connection\n",
    "\n",
    "Replacing the mean \\(\\mathbb{E}[X]\\) with a linear predictor \\(x\\beta\\) gives the usual regression form:\n",
    "$$\n",
    "X = x\\beta + \\text{error}.\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
