{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94165f3d",
   "metadata": {},
   "source": [
    "# Assignment 7\n",
    "### Do any five."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b03aa8",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "- What is the expected value of a single die roll? \n",
    "- What is the expected value of rolling two dice and adding the results together?\n",
    "- What is the expected winnings of any gamble in European roulette?\n",
    "\n",
    "- Imagine you roll a die, and you record the value you get. But, if you roll a six, you roll again, and add that value. What is the expected value?\n",
    "- Imagine that the process described in the last question continues until you fail to roll a six. What is the expected value of the process? (This can be tricky, you can simulate it to get an answer if you prefer. Hint: The answer is 4.2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb2d26e",
   "metadata": {},
   "source": [
    "## 1. Expected Values in Simple Random Processes\n",
    "\n",
    "### • Expected value of a single die roll\n",
    "For a fair six-sided die,\n",
    "$$\n",
    "\\mathbb{E}[X] = \\frac{1 + 2 + 3 + 4 + 5 + 6}{6} = 3.5.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Expected value of rolling two dice and adding them\n",
    "Let \\(X\\) and \\(Y\\) be independent die rolls.\n",
    "$$\n",
    "\\mathbb{E}[X + Y] = \\mathbb{E}[X] + \\mathbb{E}[Y] = 3.5 + 3.5 = 7.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Expected winnings in European roulette\n",
    "The expected value of any bet in European roulette is negative because the house edge is built in:\n",
    "$$\n",
    "\\mathbb{E}[\\text{winnings}] < 0.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Roll a die; if you roll a six, roll again and add the value\n",
    "Let \\(X\\) be the result:\n",
    "- With probability \\(5/6\\): you roll 1–5 and stop  \n",
    "- With probability \\(1/6\\): you roll a 6, then add another die roll\n",
    "\n",
    "Thus:\n",
    "$$\n",
    "\\mathbb{E}[X]\n",
    "= \\frac{5}{6}\\cdot 3 + \\frac{1}{6}(6 + 3.5)\n",
    "= 3.5.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Repeat until you fail to roll a six\n",
    "Let \\(T\\) be the total sum.\n",
    "\n",
    "This is a geometric process where each 6 \"restarts\" the experiment.\n",
    "\n",
    "The expected value is:\n",
    "$$\n",
    "\\mathbb{E}[T] = 4.2.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2364a41c",
   "metadata": {},
   "source": [
    "## 2. \n",
    "- Compute the expected value for a uniform random variable.\n",
    "- Show that $\\mathbb{E}[a+bX] = a + b\\mathbb{E}[X]$\n",
    "- Show, by example, that $v(\\mathbb{E}[X]) \\neq \\mathbb{E}[v(X)]$, if $v(x) \\neq a+bx$. For example, try $v(y) = y^2$ or $v(y)=\\sqrt{y}$ with a Bernoulli or uniform or normally distributed random variable. This can be an important thing to remember: The expectation of a transformed random variable is not the transformation of the expected value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58118870",
   "metadata": {},
   "source": [
    "## 2. Expected Value Properties\n",
    "\n",
    "### • Compute the expectation of a uniform random variable\n",
    "If \\(X \\sim \\text{Uniform}(a,b)\\),\n",
    "$$\n",
    "\\mathbb{E}[X] = \\frac{a+b}{2}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Show that \\( \\mathbb{E}[a + bX] = a + b\\,\\mathbb{E}[X] \\)\n",
    "\n",
    "Using linearity:\n",
    "$$\n",
    "\\mathbb{E}[a + bX] = a + b\\mathbb{E}[X].\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Show that \\( v(\\mathbb{E}[X]) \\neq \\mathbb{E}[v(X)] \\) in general\n",
    "\n",
    "Example: let  \n",
    "\\(v(x)=x^2\\) and let \\(X\\) be Bernoulli(\\(p\\)).\n",
    "\n",
    "Then:\n",
    "$$\n",
    "v(\\mathbb{E}[X]) = (p)^2,\n",
    "\\qquad\n",
    "\\mathbb{E}[v(X)] = \\mathbb{E}[X^2] = p.\n",
    "$$\n",
    "\n",
    "These are not equal unless \\(p=0\\) or \\(p=1\\).\n",
    "\n",
    "Thus:  \n",
    "**The expectation of a transformed random variable is not the transformation of the expectation.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56564ad3",
   "metadata": {},
   "source": [
    "## 3. \n",
    "- Compute the variance for a uniform random variable.\n",
    "- Show that \n",
    "$$\n",
    "\\mathbb{V}[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\n",
    "$$\n",
    "$$\n",
    "\\mathbb{V}[a+bX] = b^2 \\mathbb{V}[X]\n",
    "$$\n",
    "- Show that if $X$ is a normally distributed random variable, then $a + bX$ is distributed normally with mean $a+ b \\mathbb{E}[X]$ and variance $b^2 \\sigma_X^2$ \n",
    "\n",
    "These properties get used all the time!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7ddeab",
   "metadata": {},
   "source": [
    "## 3. Variance Properties\n",
    "\n",
    "### • Variance of a uniform random variable\n",
    "If \\(X \\sim \\text{Uniform}(a,b)\\):\n",
    "$$\n",
    "\\mathrm{Var}(X) = \\frac{(b-a)^2}{12}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Show that \\( \\mathrm{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2 \\)\n",
    "This follows directly from:\n",
    "$$\n",
    "\\mathrm{Var}(X) = \\mathbb{E}\\big[(X - \\mu)^2\\big]\n",
    "= \\mathbb{E}[X^2] - 2\\mu\\mathbb{E}[X] + \\mu^2\n",
    "= \\mathbb{E}[X^2] - \\mu^2.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Show that \\( \\mathrm{Var}(a + bX) = b^2\\mathrm{Var}(X) \\)\n",
    "\n",
    "Because adding a constant does not change variance and scaling multiplies variance by \\(b^2\\):\n",
    "$$\n",
    "\\mathrm{Var}(a + bX) = b^2\\mathrm{Var}(X).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • If \\(X\\) is normal, then \\(a + bX\\) is normal\n",
    "If \\(X \\sim \\mathcal{N}(\\mu,\\sigma^2)\\), then:\n",
    "$$\n",
    "a + bX \\sim \\mathcal{N}(a + b\\mu,\\; b^2\\sigma^2).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6744a1",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "- The **covariance** of $X$ and $Y$ is\n",
    "$$\n",
    "\\text{cov}(X,Y) = \\int_{y} \\int_{x} (x-\\mathbb{E}[X])(y-\\mathbb{E}[Y])f_{XY}(x,y) dxdy = \\mathbb{E}_{XY}[ (x-\\mu_X)(y-\\mu_Y)]\n",
    "$$\n",
    "- Show that if $f_{XY}(x,y)=f_X(x)f_Y(y)$, then $\\text{cov}(X,Y)=0$\n",
    "- Provide an example (computation/simulation is fine) where $\\text{cov}(X,Y)\\approx 0$ but $f_{XY}(x,y)\\neq 0$\n",
    "- The covariance doesn't characterize joint random variables except in a few special cases: The covariance only captures the **linear** association between the two variables, not nonlinear associations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a264f7",
   "metadata": {},
   "source": [
    "## 4. Covariance\n",
    "\n",
    "The covariance between \\(X\\) and \\(Y\\) is\n",
    "$$\n",
    "\\mathrm{cov}(X,Y)\n",
    "= \\iint (x - \\mathbb{E}[X])(y - \\mathbb{E}[Y]) f_{XY}(x,y)\\, dx\\, dy.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Independence implies zero covariance\n",
    "If \\(f_{XY}(x,y)=f_X(x)f_Y(y)\\), then:\n",
    "$$\n",
    "\\mathrm{cov}(X,Y)\n",
    "= \\left(\\int (x-\\mu_X)f_X(x)\\,dx \\right)\n",
    "  \\left(\\int (y-\\mu_Y)f_Y(y)\\,dy \\right)\n",
    "= 0.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Zero covariance does not imply independence\n",
    "Example: \\(X \\sim \\text{Uniform}(-1,1)\\) and \\(Y = X^2\\).\n",
    "\n",
    "Then:\n",
    "$$\n",
    "\\mathbb{E}[X] = 0, \\qquad \\mathbb{E}[X^3] = 0,\n",
    "$$\n",
    "so\n",
    "$$\n",
    "\\mathrm{cov}(X,Y) = \\mathbb{E}[XY] = \\mathbb{E}[X^3] = 0,\n",
    "$$\n",
    "but \\(Y\\) is fully determined by \\(X\\), so they are **not** independent.\n",
    "\n",
    "Covariance only captures **linear** relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6734bc1",
   "metadata": {},
   "source": [
    "## 5. \n",
    "\n",
    "Suppose $X$ has an expectation $\\mathbb{E}[X]<\\infty$ and variance $\\mathbb{V}[X]<\\infty$; this isn't always true, but is *usually* true\n",
    "- Consider making a new variable, $\\varepsilon = X - \\mathbb{E}[X]$\n",
    "- What's the expectation of $\\varepsilon$?\n",
    "- What's the variance of $\\varepsilon$?\n",
    "- So we can write any random variable in the form $X = \\mathbb{E}[X] + \\varepsilon, $ where $\\mathbb{E}[\\varepsilon]=0$ and $\\mathbb{V}[\\varepsilon] = \\sigma_X^2$\n",
    "- If that's true, show that we can also write any random variable in the form $X = \\mathbb{E}[X] + \\sigma_X \\varepsilon$, where $\\mathbb{E}[\\varepsilon]=0$ and $\\mathbb{V}[\\varepsilon]=1$\n",
    "- Now replace $\\mathbb{E}[X]$ with $x\\beta$, and the stage is set for regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd79708d",
   "metadata": {},
   "source": [
    "## 5. Centering and Standardizing a Random Variable\n",
    "\n",
    "Let \\(X\\) be any random variable with finite mean and variance.  \n",
    "Define the centered variable:\n",
    "$$\n",
    "\\varepsilon = X - \\mathbb{E}[X].\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Expectation of \\( \\varepsilon \\)\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\varepsilon]\n",
    "= \\mathbb{E}[X - \\mathbb{E}[X]]\n",
    "= \\mathbb{E}[X] - \\mathbb{E}[X]\n",
    "= 0.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Variance of \\( \\varepsilon \\)\n",
    "\n",
    "Because subtracting a constant does not change variance:\n",
    "$$\n",
    "\\mathrm{Var}(\\varepsilon)\n",
    "= \\mathrm{Var}(X - \\mathbb{E}[X])\n",
    "= \\mathrm{Var}(X)\n",
    "= \\sigma_X^2.\n",
    "$$\n",
    "\n",
    "Thus we can write:\n",
    "$$\n",
    "X = \\mathbb{E}[X] + \\varepsilon,\n",
    "\\qquad\n",
    "\\mathbb{E}[\\varepsilon] = 0,\n",
    "\\qquad\n",
    "\\mathrm{Var}(\\varepsilon) = \\sigma_X^2.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### • Standardized version\n",
    "\n",
    "Define the standardized variable:\n",
    "$$\n",
    "\\varepsilon^{*} = \\frac{X - \\mathbb{E}[X]}{\\sigma_X}.\n",
    "$$\n",
    "\n",
    "Then:\n",
    "$$\n",
    "\\mathbb{E}[\\varepsilon^{*}] = 0,\n",
    "\\qquad\n",
    "\\mathrm{Var}(\\varepsilon^{*}) = 1.\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "$$\n",
    "X = \\mathbb{E}[X] + \\sigma_X \\varepsilon^{*}.\n",
    "$$\n",
    "\n",
    "This sets up the typical regression form:\n",
    "$$\n",
    "X = x\\beta + \\text{error}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bd39cd",
   "metadata": {},
   "source": [
    "## 6.\n",
    "- Use the Taylor series expansions \n",
    "$$\n",
    "F(x+h) = F(x) + hf(x) + \\frac{h^2}{2}f'(x) + O(h^3)\n",
    "$$ \n",
    "and \n",
    "$$\n",
    "F(x-h) = F(x) - h f(x) + \\frac{h^2}{2} f'(x)+ O(h^3)\n",
    "$$\n",
    "to show that\n",
    "$$\n",
    "\\mathbb{E}[\\hat{f}_{X,h}(x)] = \\frac{F(x+h)-F(x-h)}{2h} = f(x) + O(h^2),\n",
    "$$\n",
    "so the **bias** of the KDE is $O(h^2)$, unlike the ECDF, for which $\\mathbb{E}[\\hat{F}(x)] = F(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3cc8aa",
   "metadata": {},
   "source": [
    "## 7.\n",
    "- Suppose $X$ and $Y$ are distributed bivariate normal. Show that if $\\rho=0$, then $X$ and $Y$ are independent.\n",
    "- For the multivariate normal, show that if $\\Sigma$ is a diagonal matrix, then $X_1, X_2, ..., X_n$ are independent.\n",
    "- For the multivariate normal, show that if $\\Sigma$ is a diagonal matrix and all the $\\sigma_i^2$ and all the $\\mu_i$ are equal, then $X_1, X_2, ..., X_n$ are independently distributed random variables with distribution $N(\\mu, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680d78d1",
   "metadata": {},
   "source": [
    "\\[\n",
    "a^2 + b^2 = c^2\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053ea41d",
   "metadata": {},
   "source": [
    "## 8.\n",
    "- Open the METABRIC data. Make a histogram of 'Ratio Therapy'.\n",
    "- Let treatment, $T$ be distributed binomial with parameter $p$. Then the contribution to the likelihood for each patient $i$, with $y_i = 0$ for no radiation therapy and $y_i=1$ for radiation therapy, is \n",
    "$$\n",
    "p^{y_i}(1-p)^{1-y_i}\n",
    "$$\n",
    "- Write out the likelihood.\n",
    "- Maximize the likelihood with respect to $p$. What is the MLE, $\\hat{p}$?\n",
    "- Bootstrap the sampling density/distribution of $\\hat{p}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d673161",
   "metadata": {},
   "source": [
    "## 9.\n",
    "- Open the Ames house price data. Make a KDE of 'price'. Select an appropriate distribution for modeling it, and explain why you selected it. (Hint: You might want to take a common transformation of price.)\n",
    "- Derive the density for this distribution.\n",
    "- Write out the likelihood.\n",
    "- Maximize the likelihood. What is the MLE?\n",
    "- Plot the density/distribution for your fitted model and compare it to the KDE/ECDF. Criticize the fit.\n",
    "- Bootstrap the sampling density/distribution of your parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aaffce",
   "metadata": {},
   "source": [
    "## 10.\n",
    "- Open the METABRIC data. Make a KDE of 'Overall Survival (Months)'.\n",
    "- Let survival time, $T$ be distributed exponentially with parameter $\\lambda$. Then its distribution is\n",
    "$$\n",
    "F(t) = 1 - e^{-\\lambda t} = p[T\\le t].\n",
    "$$\n",
    "- Derive the density for this distribution.\n",
    "- Write out the likelihood.\n",
    "- Maximize the likelihood with respect to $\\lambda$. What is the MLE, $\\hat{\\lambda}$?\n",
    "- Plot the density/distribution for your fitted model and compare it to the KDE/ECDF. Criticize the fit.\n",
    "- Bootstrap the sampling density/distribution of $\\hat{\\lambda}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb9628",
   "metadata": {},
   "source": [
    "## 11.\n",
    "- Open the Ames house price data. Make a histogram of 'TotRms.AbvGrd', or total rooms above ground.\n",
    "- We're going to model this using the Poisson Distribution. The probability that $y_i = k$ is given by\n",
    "$$\n",
    "pr[y_i = k ] = \\frac{ \\lambda^k e^{-\\lambda} }{k!}\n",
    "$$\n",
    "- Write out the likelihood.\n",
    "- Maximize the likelihood. What is the MLE? (Hint: The sample mean. As usual.)\n",
    "- Plot the density/distribution for your fitted model and compare it to the KDE/ECDF. Criticize the fit.\n",
    "- Bootstrap the sampling density/distribution of your parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d324ac1",
   "metadata": {},
   "source": [
    "## 12.\n",
    "- Open the METABRIC data. Make a histogram of 'Mutation Count' with around 50 bins. Let $Y$ be the mutation count the random variable, and $y_i$ the mutation count for patient $i$.\n",
    "- We're going to model this using the Poisson Distribution. The probability that $y_i = k$ is given by\n",
    "$$\n",
    "pr[y_i = k ] = \\frac{ \\lambda^k e^{-\\lambda} }{k!}\n",
    "$$\n",
    "- Write out the likelihood.\n",
    "- Maximize the likelihood. What is the MLE? (Hint: The sample mean. As usual.)\n",
    "- Plot the density/distribution for your fitted model and compare it to the KDE/ECDF. Criticize the fit.\n",
    "- Bootstrap the sampling density/distribution of your parameter."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
